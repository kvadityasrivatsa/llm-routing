{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f15cd1c2-d81c-49df-97fd-6b78dc0ecab7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from random import randint\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.utils.class_weight import compute_class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b01fed75-da6e-4bcb-938a-8ee87a5111a5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8792, 6) (1319, 6) gsm8k\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>split</th>\n",
       "      <th>true_label</th>\n",
       "      <th>prediction</th>\n",
       "      <th>raw_predictions</th>\n",
       "      <th>confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Natalia sold clips to 48 of her friends in Apr...</td>\n",
       "      <td>train</td>\n",
       "      <td>['maj_gemma-7b-it_CHAT', 'maj_gemma-7b_LM', 'm...</td>\n",
       "      <td>['maj_gemma-7b-it_CHAT', 'maj_gemma-7b_LM', 'm...</td>\n",
       "      <td>[1 1 1 1 1 1]</td>\n",
       "      <td>[0.3574865 3.1160297 1.3018662 3.9527552 1.378...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Weng earns $12 an hour for babysitting. Yester...</td>\n",
       "      <td>train</td>\n",
       "      <td>['maj_gemma-7b_LM', 'maj_metamath-7b_LM', 'maj...</td>\n",
       "      <td>['maj_gemma-7b-it_CHAT', 'maj_gemma-7b_LM', 'm...</td>\n",
       "      <td>[1 1 1 1 1 1]</td>\n",
       "      <td>[1.1924486 3.2154894 1.7751658 3.3046634 1.896...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Betty is saving money for a new wallet which c...</td>\n",
       "      <td>train</td>\n",
       "      <td>['maj_gemma-7b_LM', 'maj_llama2-13b-chat_CHAT'...</td>\n",
       "      <td>['maj_gemma-7b-it_CHAT', 'maj_gemma-7b_LM', 'm...</td>\n",
       "      <td>[1 1 1 1 1 1]</td>\n",
       "      <td>[0.3417136 2.9823468 1.1348128 3.8447897 1.254...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Julie is reading a 120-page book. Yesterday, s...</td>\n",
       "      <td>train</td>\n",
       "      <td>['maj_gemma-7b-it_CHAT', 'maj_gemma-7b_LM', 'm...</td>\n",
       "      <td>['maj_gemma-7b_LM', 'maj_metamath-7b_LM', 'maj...</td>\n",
       "      <td>[0 1 0 1 0 1]</td>\n",
       "      <td>[-1.2804217   1.9825261  -0.03160543  3.822210...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>James writes a 3-page letter to 2 different fr...</td>\n",
       "      <td>train</td>\n",
       "      <td>['maj_metamath-7b_LM']</td>\n",
       "      <td>['maj_gemma-7b_LM', 'maj_metamath-7b_LM', 'maj...</td>\n",
       "      <td>[0 1 0 1 0 1]</td>\n",
       "      <td>[-1.8108426   1.4010394  -0.44269687  3.527691...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  split  \\\n",
       "0  Natalia sold clips to 48 of her friends in Apr...  train   \n",
       "1  Weng earns $12 an hour for babysitting. Yester...  train   \n",
       "2  Betty is saving money for a new wallet which c...  train   \n",
       "3  Julie is reading a 120-page book. Yesterday, s...  train   \n",
       "4  James writes a 3-page letter to 2 different fr...  train   \n",
       "\n",
       "                                          true_label  \\\n",
       "0  ['maj_gemma-7b-it_CHAT', 'maj_gemma-7b_LM', 'm...   \n",
       "1  ['maj_gemma-7b_LM', 'maj_metamath-7b_LM', 'maj...   \n",
       "2  ['maj_gemma-7b_LM', 'maj_llama2-13b-chat_CHAT'...   \n",
       "3  ['maj_gemma-7b-it_CHAT', 'maj_gemma-7b_LM', 'm...   \n",
       "4                             ['maj_metamath-7b_LM']   \n",
       "\n",
       "                                          prediction raw_predictions  \\\n",
       "0  ['maj_gemma-7b-it_CHAT', 'maj_gemma-7b_LM', 'm...   [1 1 1 1 1 1]   \n",
       "1  ['maj_gemma-7b-it_CHAT', 'maj_gemma-7b_LM', 'm...   [1 1 1 1 1 1]   \n",
       "2  ['maj_gemma-7b-it_CHAT', 'maj_gemma-7b_LM', 'm...   [1 1 1 1 1 1]   \n",
       "3  ['maj_gemma-7b_LM', 'maj_metamath-7b_LM', 'maj...   [0 1 0 1 0 1]   \n",
       "4  ['maj_gemma-7b_LM', 'maj_metamath-7b_LM', 'maj...   [0 1 0 1 0 1]   \n",
       "\n",
       "                                          confidence  \n",
       "0  [0.3574865 3.1160297 1.3018662 3.9527552 1.378...  \n",
       "1  [1.1924486 3.2154894 1.7751658 3.3046634 1.896...  \n",
       "2  [0.3417136 2.9823468 1.1348128 3.8447897 1.254...  \n",
       "3  [-1.2804217   1.9825261  -0.03160543  3.822210...  \n",
       "4  [-1.8108426   1.4010394  -0.44269687  3.527691...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading prediction file\n",
    "\n",
    "data_name = \"gsm8k\"\n",
    "# data_name = \"mmlu\"\n",
    "\n",
    "path = \"../data/routing_classifier_predictions\"\n",
    "\n",
    "if data_name == \"gsm8k\":\n",
    "    filename = \"gsm8k_cls_predictions.csv\"\n",
    "elif data_name == \"mmlu\":\n",
    "    filename = \"mmlu_cls_predictions.csv\"\n",
    "else:\n",
    "    raise Exception(f\"Dataset -- {data_name} not found.\")\n",
    "\n",
    "data_all= pd.read_csv(os.path.join(path,filename), encoding=\"utf-8\")\n",
    "data = data_all.loc[data_all['split'] == 'test']\n",
    "print(data_all.shape, data.shape, data_name)\n",
    "data_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0668dca-7efe-445a-8b25-c7ae0ab22b4a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['maj_gemma-7b-it_CHAT', 'maj_gemma-7b_LM', 'maj_llama2-13b-chat_CHAT', 'maj_metamath-7b_LM', 'maj_mistral-7b-inst_CHAT', 'maj_mistral-7b-lm_LM']\n",
      "[1 1 1 1 1 1]\n",
      "{0: 'maj_gemma-7b-it_CHAT', 1: 'maj_gemma-7b_LM', 2: 'maj_llama2-13b-chat_CHAT', 3: 'maj_metamath-7b_LM', 4: 'maj_mistral-7b-inst_CHAT', 5: 'maj_mistral-7b-lm_LM'}\n",
      "{'maj_gemma-7b-it_CHAT': 0, 'maj_gemma-7b_LM': 1, 'maj_llama2-13b-chat_CHAT': 2, 'maj_metamath-7b_LM': 3, 'maj_mistral-7b-inst_CHAT': 4, 'maj_mistral-7b-lm_LM': 5}\n"
     ]
    }
   ],
   "source": [
    "#change as per the need\n",
    "\n",
    "if data_name == 'gsm8k':\n",
    "    llms = eval(data_all['prediction'].values.tolist()[1])\n",
    "    print(llms)\n",
    "    print(data_all['raw_predictions'].values.tolist()[1])\n",
    "    id2mod = {i:val for i, val in enumerate(llms)}\n",
    "    mod2id = {val:i for i, val in enumerate(llms)}\n",
    "    mod2lat = {'maj_gemma-7b-it_CHAT':0.70,  'maj_gemma-7b_LM':7.10, 'maj_llama2-13b-chat_CHAT':1.80, 'maj_metamath-7b_LM':4.70, 'maj_mistral-7b-inst_CHAT':1.00, 'maj_mistral-7b-lm_LM':3.70}\n",
    "elif data_name == 'mmlu':\n",
    "    llms = eval(data_all['prediction'].values.tolist()[11102])\n",
    "    print(llms)\n",
    "    print(data_all['raw_predictions'].values.tolist()[11102])\n",
    "    id2mod = {i:val for i, val in enumerate(llms)}\n",
    "    mod2id = {val:i for i, val in enumerate(llms)}\n",
    "    mod2lat = {'maj_gemma-7b-it_CHAT':1.00,  \"maj_llama2-7b-lm_LM\":2.30, 'maj_gemma-7b_LM':3.00, 'maj_llama2-13b-chat_CHAT':4.80, 'maj_metamath-7b_LM':2.40, 'maj_mistral-7b-inst_CHAT':1.10, 'maj_mistral-7b-lm_LM':1.80}\n",
    "    \n",
    "print(id2mod)\n",
    "print(mod2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9bcb111d-2ed1-4d5a-9775-2539b59d6f21",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the Test Set: 1319\n",
      "Ground Truth Sample: [[0, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 0], [0, 1, 0, 1, 1, 1], [0, 1, 0, 1, 0, 0], [0, 0, 0, 1, 1, 0], [1, 1, 1, 0, 1, 1], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1]]\n",
      "Predictions Sample: [[0, 1, 0, 1, 0, 0], [0, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1], [0, 1, 0, 1, 0, 0], [0, 1, 0, 1, 0, 0], [0, 1, 1, 1, 1, 1], [0, 0, 0, 1, 0, 0], [0, 0, 0, 1, 0, 0], [0, 1, 0, 1, 1, 0]]\n",
      "Confidence Sample: [[-2.2803745, 0.19979207, -1.4978793, 2.4199407, -1.5842866, -0.6895504], [-0.386041, 2.6517174, 0.47759134, 4.136191, 1.0317405, 1.5089911]]\n",
      "Model Details: ['maj_gemma-7b-it_CHAT', 'maj_gemma-7b_LM', 'maj_llama2-13b-chat_CHAT', 'maj_metamath-7b_LM', 'maj_mistral-7b-inst_CHAT', 'maj_mistral-7b-lm_LM']\n"
     ]
    }
   ],
   "source": [
    "# Collecting ground Truth, Predictions, and confidence scores\n",
    "Global_List = []\n",
    "\n",
    "def clean(labels, flag):\n",
    "    if flag == 'conf':\n",
    "        elabels = [list(map(float, re.findall(r'-?\\d+(?:\\.\\d+)?(?:[eE][+\\-]?\\d+)?', s))) for s in labels]\n",
    "    else:\n",
    "        elabels = [list(map(int, item.strip('[]').split(' '))) for item in labels]    \n",
    "    return elabels\n",
    "        \n",
    "\n",
    "truth = [ [1 if element in item else 0 for element in llms]  for item in data['true_label'].tolist()]\n",
    "pred = [ [1 if element in item else 0 for element in llms]  for item in data['prediction'].tolist()]\n",
    "\n",
    "pred_check =  clean(data['raw_predictions'].tolist(), 'pred')\n",
    "raw_conf = clean(data['confidence'].tolist(), 'conf')\n",
    "\n",
    "assert len(truth) == len(pred) == len(pred_check) == len(raw_conf)\n",
    "for p, pc in zip(pred, pred_check):\n",
    "    if p != pc:\n",
    "        print(p,pc)\n",
    "\n",
    "print(\"Length of the Test Set:\", len(pred))\n",
    "print(\"Ground Truth Sample:\", truth[:10])\n",
    "print(\"Predictions Sample:\", pred[:10])\n",
    "print(\"Confidence Sample:\", raw_conf[:2])\n",
    "print(\"Model Details:\", llms)\n",
    "Global_List.append(['Considered LLMs', llms, '---'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c9c1b45-e5ba-4b81-ace8-0f75840ac5da",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maj_gemma-7b-it_CHAT 1.7108979483080202\n",
      "maj_gemma-7b_LM 0.810425343935378\n",
      "maj_llama2-13b-chat_CHAT 1.2322011130301285\n",
      "maj_metamath-7b_LM 0.6479967706125744\n",
      "maj_mistral-7b-inst_CHAT 1.193716304145752\n",
      "maj_mistral-7b-lm_LM 1.0110218863171154\n"
     ]
    }
   ],
   "source": [
    "# Assuming data_all is a pandas DataFrame with a column named \"true_label\"\n",
    "# containing the multi-label data as strings\n",
    "data_train = data_all.loc[data_all['split'] == 'train']\n",
    "all_lab = [eval(item) for item in data_train[\"true_label\"].tolist()]\n",
    "# Flatten the label tensors into a single list\n",
    "all_labels = [label for label_tensor in all_lab for label in label_tensor]\n",
    "\n",
    "res = compute_class_weight(class_weight=\"balanced\", classes=np.unique(all_labels), y=all_labels)\n",
    "for n, v in zip(np.unique(all_labels), res):\n",
    "    print(n, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30c4613b-9dee-4190-9b6f-d00ece17e04c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "    maj_gemma-7b-it_CHAT       0.56      0.46      0.51       486\n",
      "         maj_gemma-7b_LM       0.76      0.86      0.81       938\n",
      "maj_llama2-13b-chat_CHAT       0.61      0.62      0.62       616\n",
      "      maj_metamath-7b_LM       0.68      1.00      0.81       891\n",
      "maj_mistral-7b-inst_CHAT       0.64      0.61      0.63       665\n",
      "    maj_mistral-7b-lm_LM       0.73      0.72      0.73       788\n",
      "\n",
      "               micro avg       0.68      0.75      0.71      4384\n",
      "               macro avg       0.66      0.71      0.68      4384\n",
      "            weighted avg       0.68      0.75      0.71      4384\n",
      "             samples avg       0.63      0.63      0.58      4384\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kvaditya/miniconda3/envs/its_v1/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kvaditya/miniconda3/envs/its_v1/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#classification report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(truth, pred, target_names=llms))\n",
    "Global_List.append(['Classifier-f1-weighted', f1_score(truth, pred, average='weighted'), '000'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c154b17c-9ca2-4fa5-b4d1-1935035b5cf1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence Sample: [[0.09276143160787238, 0.5497825306584028, 0.18274203173045825, 0.9183352974108966, 0.1701892513538227, 0.3341330964687599], [0.404670711534072, 0.9341167626651471, 0.6171789437030931, 0.9842678395313634, 0.7372531888936387, 0.8189116397889744], [0.17980583862465088, 0.22932150823237127, 0.20091072785399008, 0.411763544207105, 0.20542057281884493, 0.20359967368149376], [0.6837884209103208, 0.9613524384272092, 0.8449381421616206, 0.9742395186807706, 0.8485207387632288, 0.9315968002616676], [0.0732129976165776, 0.5377422250936039, 0.18734527836434933, 0.9193480281483987, 0.16308518765599958, 0.3142760719112152]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def softmax_manual(scores):\n",
    "    exp_scores = np.exp(scores - np.max(scores))\n",
    "    return exp_scores / exp_scores.sum(axis=0)\n",
    "\n",
    "def sigmoid(scores):\n",
    "    return [(1 / (1 + math.exp(-x))) for x in scores]\n",
    "\n",
    "\n",
    "conf = [sigmoid(item) for item in raw_conf]\n",
    "print(\"Confidence Sample:\", conf[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14bf6573-a95f-4884-a052-b800abb51f68",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********** Ground Truth Label Distribution *************\n",
      "maj_gemma-7b_LM: 938 times (71.11%)\n",
      "maj_llama2-13b-chat_CHAT: 616 times (46.70%)\n",
      "maj_metamath-7b_LM: 891 times (67.55%)\n",
      "maj_mistral-7b-inst_CHAT: 665 times (50.42%)\n",
      "maj_mistral-7b-lm_LM: 788 times (59.74%)\n",
      "maj_gemma-7b-it_CHAT: 486 times (36.85%)\n",
      "\n",
      "*********** Prediction Label Distribution ****************\n",
      "maj_gemma-7b_LM: 1067 times (80.89%)\n",
      "maj_metamath-7b_LM: 1314 times (99.62%)\n",
      "maj_llama2-13b-chat_CHAT: 624 times (47.31%)\n",
      "maj_mistral-7b-inst_CHAT: 634 times (48.07%)\n",
      "maj_mistral-7b-lm_LM: 778 times (58.98%)\n",
      "maj_gemma-7b-it_CHAT: 398 times (30.17%)\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def lab_dist(all_in):\n",
    "    temp = [ [ id2mod[i] for i, val in enumerate(item) if val !=0 ] for item in all_in]\n",
    "    flattened_list = [item for sublist in temp for item in sublist]\n",
    "\n",
    "    # Count the occurrences of each element\n",
    "    element_counts = Counter(flattened_list)\n",
    "\n",
    "    # Display the counts\n",
    "    for element, count in element_counts.items():\n",
    "        percentage = (count / len(all_in)) * 100\n",
    "        print(f\"{element}: {count} times ({percentage:.2f}%)\")\n",
    "\n",
    "print(\"*********** Ground Truth Label Distribution *************\")\n",
    "lab_dist(truth)\n",
    "print(\"\")\n",
    "print(\"*********** Prediction Label Distribution ****************\")\n",
    "lab_dist(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88f35b89-6fe5-418f-8d1e-f2653336b717",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** Running Orecle Model *********\n",
      "Max Accuracy (%) :  87.18726307808946\n",
      "Min Latency (Sec/Prompt) :  3.859391304347826\n"
     ]
    }
   ],
   "source": [
    "print(\"********** Running Orecle Model *********\")\n",
    "# Oracle Model: Always selct best model\n",
    "def oreacle(all_lab):\n",
    "    acc_count = 0\n",
    "    temp_count = 0\n",
    "    llm_count = len(llms)*[0]\n",
    "    for lab in all_lab:\n",
    "        for i, val in enumerate(lab):\n",
    "            if val == 1:\n",
    "                acc_count += 1\n",
    "                llm_count[i] += 1\n",
    "                break\n",
    "            if i ==len(llms)-1:\n",
    "                temp_count += 1 \n",
    "   \n",
    "    assert temp_count + sum(llm_count) == len(all_lab)\n",
    "    return acc_count, llm_count\n",
    "        \n",
    "\n",
    "acc, llm_count_list = oreacle(truth)\n",
    "facc = acc/(len(truth))\n",
    "lat = sum([ item* mod2lat[id2mod[i]] for i, item in enumerate(llm_count_list)])\n",
    "flat=lat/sum(llm_count_list)\n",
    "print(\"Max Accuracy (%) : \", facc*100)\n",
    "print(\"Min Latency (Sec/Prompt) : \", flat)\n",
    "\n",
    "Global_List.append(['Oracle', facc*100, flat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "345cc395-a8f1-4b65-bb83-a43810508236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Running Random Model ************\n",
      "Max Accuracy (100) :  55.37801364670209\n",
      "Latency (Sec/Prompt) :  3.6233322536554033\n"
     ]
    }
   ],
   "source": [
    "print(\"***********Running Random Model ************\")\n",
    "\n",
    "def random(all_lab):\n",
    "    acc_count = 0\n",
    "    temp_count = 0\n",
    "    llm_count = len(llms)*[0]\n",
    "    for lab in all_lab:\n",
    "        random_index = randint(0, len(lab) - 1)\n",
    "        if lab[random_index] >= 0.8:\n",
    "            acc_count += 1\n",
    "            llm_count[random_index] += 1\n",
    "        else:\n",
    "            temp_count += 1 \n",
    "            \n",
    "    assert temp_count + sum(llm_count) == len(all_lab)\n",
    "    return acc_count, llm_count\n",
    "        \n",
    "acc_list, lat_list = [],[]\n",
    "for i in range(1000): \n",
    "    acc, llm_count_list = random(truth)\n",
    "    facc = acc/(len(truth))\n",
    "    lat = sum([ item*mod2lat[id2mod[i]] for i, item in enumerate(llm_count_list)])\n",
    "    flat=lat/sum(llm_count_list)\n",
    "    acc_list.append(facc)\n",
    "    lat_list.append(flat)\n",
    "\n",
    "print(\"Max Accuracy (100) : \", sum(acc_list)/len(acc_list)*100)\n",
    "print(\"Latency (Sec/Prompt) : \", sum(lat_list)/len(lat_list))\n",
    "\n",
    "Global_List.append(['Random', sum(acc_list)/len(acc_list)*100,  sum(lat_list)/len(lat_list)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "93a6675b-cd03-44e5-80a0-9206bee195eb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** Running Different Baseline Models *********\n",
      "Configurations: [[0], [1], [2], [3], [4], [5], [0, 3], [1, 3], [2, 4], [1, 3, 4], [0, 1, 4], [0, 4, 5], [0, 2, 5], [1, 2, 3, 4], [0, 1, 2, 5], [0, 2, 4, 5], [0, 1, 2, 3, 4, 5]]\n",
      "Current Model is/are: ['maj_gemma-7b-it_CHAT']\n",
      "Max Accuracy (%) :  36.84609552691433\n",
      "Min Latency (Sec/Prompt) :  0.7\n",
      "Current Model is/are: ['maj_gemma-7b_LM']\n",
      "Max Accuracy (%) :  71.1144806671721\n",
      "Min Latency (Sec/Prompt) :  7.1\n",
      "Current Model is/are: ['maj_llama2-13b-chat_CHAT']\n",
      "Max Accuracy (%) :  46.70204700530705\n",
      "Min Latency (Sec/Prompt) :  1.7999999999999998\n",
      "Current Model is/are: ['maj_metamath-7b_LM']\n",
      "Max Accuracy (%) :  67.55117513267626\n",
      "Min Latency (Sec/Prompt) :  4.7\n",
      "Current Model is/are: ['maj_mistral-7b-inst_CHAT']\n",
      "Max Accuracy (%) :  50.41698256254739\n",
      "Min Latency (Sec/Prompt) :  1.0\n",
      "Current Model is/are: ['maj_mistral-7b-lm_LM']\n",
      "Max Accuracy (%) :  59.74222896133434\n",
      "Min Latency (Sec/Prompt) :  3.7000000000000006\n",
      "Current Model is/are: ['maj_gemma-7b-it_CHAT', 'maj_metamath-7b_LM']\n",
      "Max Accuracy (%) :  73.08567096285064\n",
      "Min Latency (Sec/Prompt) :  2.683402489626556\n",
      "Current Model is/are: ['maj_gemma-7b_LM', 'maj_metamath-7b_LM']\n",
      "Max Accuracy (%) :  81.80439727065959\n",
      "Min Latency (Sec/Prompt) :  6.786376274328081\n",
      "Current Model is/are: ['maj_llama2-13b-chat_CHAT', 'maj_mistral-7b-inst_CHAT']\n",
      "Max Accuracy (%) :  63.00227445034117\n",
      "Min Latency (Sec/Prompt) :  1.593020457280385\n",
      "Current Model is/are: ['maj_gemma-7b_LM', 'maj_metamath-7b_LM', 'maj_mistral-7b-inst_CHAT']\n",
      "Max Accuracy (%) :  84.38210765731615\n",
      "Min Latency (Sec/Prompt) :  6.609613656783467\n",
      "Current Model is/are: ['maj_gemma-7b-it_CHAT', 'maj_gemma-7b_LM', 'maj_mistral-7b-inst_CHAT']\n",
      "Max Accuracy (%) :  78.46853677028052\n",
      "Min Latency (Sec/Prompt) :  3.7588405797101445\n",
      "Current Model is/are: ['maj_gemma-7b-it_CHAT', 'maj_mistral-7b-inst_CHAT', 'maj_mistral-7b-lm_LM']\n",
      "Max Accuracy (%) :  72.25170583775588\n",
      "Min Latency (Sec/Prompt) :  1.317313746065058\n",
      "Current Model is/are: ['maj_gemma-7b-it_CHAT', 'maj_llama2-13b-chat_CHAT', 'maj_mistral-7b-lm_LM']\n",
      "Max Accuracy (%) :  70.28051554207732\n",
      "Min Latency (Sec/Prompt) :  1.6188781014023732\n",
      "Current Model is/are: ['maj_gemma-7b_LM', 'maj_llama2-13b-chat_CHAT', 'maj_metamath-7b_LM', 'maj_mistral-7b-inst_CHAT']\n",
      "Max Accuracy (%) :  85.44351781652767\n",
      "Min Latency (Sec/Prompt) :  6.471162377994675\n",
      "Current Model is/are: ['maj_gemma-7b-it_CHAT', 'maj_gemma-7b_LM', 'maj_llama2-13b-chat_CHAT', 'maj_mistral-7b-lm_LM']\n",
      "Max Accuracy (%) :  80.97043214556481\n",
      "Min Latency (Sec/Prompt) :  3.828183520599251\n",
      "Current Model is/are: ['maj_gemma-7b-it_CHAT', 'maj_llama2-13b-chat_CHAT', 'maj_mistral-7b-inst_CHAT', 'maj_mistral-7b-lm_LM']\n",
      "Max Accuracy (%) :  75.5117513267627\n",
      "Min Latency (Sec/Prompt) :  1.356425702811245\n",
      "Current Model is/are: ['maj_gemma-7b-it_CHAT', 'maj_gemma-7b_LM', 'maj_llama2-13b-chat_CHAT', 'maj_metamath-7b_LM', 'maj_mistral-7b-inst_CHAT', 'maj_mistral-7b-lm_LM']\n",
      "Max Accuracy (%) :  87.18726307808946\n",
      "Min Latency (Sec/Prompt) :  3.859391304347826\n"
     ]
    }
   ],
   "source": [
    "print(\"********** Running Different Baseline Models *********\")\n",
    "# Oracle Model: Always selct best model\n",
    "def baseline(all_lab):\n",
    "    acc_count = 0\n",
    "    temp_count = 0\n",
    "    llm_count = len(llms)*[0]\n",
    "    for lab in all_lab:\n",
    "        for i, val in enumerate(lab):\n",
    "            if val == 1:\n",
    "                acc_count += 1\n",
    "                llm_count[i] += 1\n",
    "                break\n",
    "            if i ==len(llms)-1:\n",
    "                temp_count += 1 \n",
    "   \n",
    "    assert temp_count + sum(llm_count) == len(all_lab)\n",
    "    return acc_count, llm_count\n",
    "        \n",
    "def all_baselines(filtered_truth):\n",
    "    acc, llm_count_list = baseline(filtered_truth)\n",
    "    facc = acc/(len(truth))\n",
    "    lat = sum([ item*mod2lat[id2mod[i]] for i, item in enumerate(llm_count_list)])\n",
    "    flat=lat/sum(llm_count_list)\n",
    "    return facc, flat\n",
    "\n",
    "\n",
    "from itertools import permutations, chain, combinations\n",
    "import random\n",
    "\n",
    "def generate_arrangements(values):\n",
    "    # Generate all permutations of lists of integers in the range (0, values)\n",
    "    arrangements = list(permutations(range(values)))\n",
    "\n",
    "    # Extract unique individual numbers\n",
    "    unique_numbers = set(chain.from_iterable(arrangements))\n",
    "    # Generate all combinations of individual numbers\n",
    "    individual_lists = [[num] for num in unique_numbers]\n",
    "\n",
    "    # Combine individual numbers to form arrangements\n",
    "    combined_arrangements = []\n",
    "    for num in list(unique_numbers):\n",
    "        if num != list(unique_numbers)[0] and num != list(unique_numbers)[-1]:\n",
    "            combined_arrangements += [list(comb) for comb in combinations(unique_numbers, num) ]\n",
    "\n",
    "    all_elements_list = list(range(values))\n",
    "    combined_arrangements.append(all_elements_list)\n",
    "\n",
    "    # Limit to 10 arrangements\n",
    "    flist = combined_arrangements[:values]\n",
    "    llist = combined_arrangements[-1]\n",
    "    mlist_temp = combined_arrangements[values:][:-1]\n",
    "    mlist = random.sample(mlist_temp, min(len(mlist_temp), 10))\n",
    "    filtered_arrangements = flist+mlist+[llist]\n",
    "    sorted_nested_list = sorted(filtered_arrangements, key=len)\n",
    "    return sorted_nested_list\n",
    "\n",
    "baseline_config = generate_arrangements(len(llms))\n",
    "if len(llms) == 2:\n",
    "    baseline_config.append([0])\n",
    "    baseline_config.append([1])\n",
    "print(\"Configurations:\", baseline_config)\n",
    "    \n",
    "for base in baseline_config:\n",
    "    filt_truth = [[val if i in base else 0 for i, val in enumerate(item)] for item in truth]\n",
    "    out_acc, out_lat = all_baselines(filt_truth)\n",
    "    Global_List.append([[ id2mod[ind] for ind in base], out_acc*100, out_lat])\n",
    "    print(\"Current Model is/are:\",  [ id2mod[ind] for ind in base])\n",
    "    print(\"Max Accuracy (%) : \", out_acc*100)\n",
    "    print(\"Min Latency (Sec/Prompt) : \", out_lat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "98d039f9-f949-4243-a8d9-d0a30c61a1ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******* Upper Bound of Performance with Optimal classifer and Policy******\n",
      "Max Accuracy (%) :  79.68157695223654\n",
      "Min Latency (Sec/Prompt) :  5.16022835394862\n"
     ]
    }
   ],
   "source": [
    "print(\"******* Upper Bound of Performance with Optimal classifer and Policy******\")\n",
    "# this will be calculated with with function as = f(prediction, ground truth)\n",
    "\n",
    "def uperbound(truth_list, pred_list):\n",
    "    acc_count, temp_count = 0, 0\n",
    "    llm_count = len(llms)*[0]\n",
    "    for i, (t, p) in enumerate(zip(truth_list, pred_list)):\n",
    "        for j, pval in enumerate(p):\n",
    "            if t[j] ==p[j] and pval == 1:\n",
    "                acc_count += 1 \n",
    "                llm_count[j] += 1\n",
    "                break\n",
    "            if j==len(llms)-1:\n",
    "                temp_count += 1      \n",
    "    assert temp_count + sum(llm_count) == len(truth_list)\n",
    "    return acc_count, llm_count\n",
    "        \n",
    "\n",
    "acc, llm_count_list = uperbound(truth, pred)\n",
    "facc = acc/(len(truth))\n",
    "lat = sum([ item*mod2lat[id2mod[i]] for i, item in enumerate(llm_count_list)])\n",
    "flat=lat/sum(llm_count_list)\n",
    "print(\"Max Accuracy (%) : \", facc*100)\n",
    "print(\"Min Latency (Sec/Prompt) : \", flat)\n",
    "\n",
    "Global_List.append(['Upperbound Performance (Classifier)', facc*100, flat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "14e4bdcc-1148-4afd-88e3-b4ceb2e56fe3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******* Proposed Policies: Policy 1: ArgMax ******\n",
      "Accuracy (%):  67.62699014404852\n",
      "Latency (Sec/Prompt) :  4.767264573991031\n"
     ]
    }
   ],
   "source": [
    "print(\"******* Proposed Policies: Policy 1: ArgMax ******\")\n",
    "# this will be calculated with with function as = f(prediction, ground truth, confidence)\n",
    "\n",
    "def policy1(pred_list, conf_list, truth_list):\n",
    "    acc_count, temp_count = 0, 0\n",
    "    llm_count = len(llms)*[0]\n",
    "    for i, (p, c, t) in enumerate(zip(pred_list, conf_list, truth_list)):\n",
    "        try: \n",
    "            maxconf_ind = c.index(max(c))\n",
    "            if p[maxconf_ind] == 1 and t[maxconf_ind] == 1:\n",
    "                acc_count += 1 \n",
    "                llm_count[maxconf_ind] += 1\n",
    "            else:\n",
    "                temp_count += 1   \n",
    "        except:\n",
    "            print(c, maxconf_ind, p, t)\n",
    "            raise Exception()\n",
    "    \n",
    "    assert temp_count + sum(llm_count) == len(pred_list)\n",
    "    return acc_count, llm_count\n",
    "        \n",
    "\n",
    "acc, llm_count_list = policy1(pred, conf, truth)\n",
    "facc = acc/(len(pred))\n",
    "lat = sum([ item*mod2lat[id2mod[i]] for i, item in enumerate(llm_count_list)])\n",
    "flat=lat/sum(llm_count_list)\n",
    "print(\"Accuracy (%): \", facc*100)\n",
    "print(\"Latency (Sec/Prompt) : \", flat)\n",
    "\n",
    "Global_List.append(['Policy1 (ConfArgMax) :', facc*100, flat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "41fae4da-f501-4612-9e29-87cbf1efdb24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******* Proposed Policies (Policy2) : random pic from top k confidance scores if confidence is less then X value ******\n",
      "Accuracy (%):  67.47536012130402\n",
      "Latency (Sec/Prompt) :  4.7674157303370785\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "print(\"******* Proposed Policies (Policy2) : random pic from top k confidance scores if confidence is less then X value ******\")\n",
    "# this will be calculated with with function as = f(prediction, ground truth, confidence)\n",
    "\n",
    "import heapq\n",
    "def top_index(my_list):\n",
    "    indices_of_highest = [my_list.index(x) for x in heapq.nlargest(3, my_list)]\n",
    "    return indices_of_highest\n",
    "\n",
    "def policy1(pred_list, conf_list, truth_list):\n",
    "    acc_count, temp_count = 0, 0\n",
    "    llm_count = len(llms)*[0]\n",
    "    for i, (p, c, t) in enumerate(zip(pred_list, conf_list, truth_list)):\n",
    "        maxconf_ind = c.index(max(c))\n",
    "        if c[maxconf_ind] <= 0.60:\n",
    "            rand_indx = random.choice(top_index(c))\n",
    "            if p[rand_indx] == 1 and t[rand_indx] == 1:\n",
    "                acc_count += 1 \n",
    "                llm_count[rand_indx] += 1\n",
    "            else:\n",
    "                temp_count += 1\n",
    "        else:\n",
    "            maxconf_ind = c.index(max(c))\n",
    "            if p[maxconf_ind] == 1 and t[maxconf_ind] == 1:\n",
    "                acc_count += 1 \n",
    "                llm_count[maxconf_ind] += 1\n",
    "            else:\n",
    "                temp_count += 1   \n",
    "    \n",
    "    assert temp_count + sum(llm_count) == len(pred_list)\n",
    "    return acc_count, llm_count\n",
    "        \n",
    "\n",
    "acc, llm_count_list = policy1(pred, conf, truth)\n",
    "facc = acc/(len(pred))\n",
    "lat = sum([ item*mod2lat[id2mod[i]] for i, item in enumerate(llm_count_list)])\n",
    "flat=lat/sum(llm_count_list)\n",
    "print(\"Accuracy (%): \", facc*100)\n",
    "print(\"Latency (Sec/Prompt) : \", flat)\n",
    "\n",
    "Global_List.append(['Policy2 (Select Random) :', facc*100, flat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "47548ff8-9815-4cbe-8751-11ceb3b22f8a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******* Proposed Policies: Policy 3: Predict output ******\n",
      "Incorect Rows: 0\n",
      "Incorect Rows: 0\n",
      "Mean Squared Error on Dev Set: 0.05219229185139534\n",
      "Accuracy (%):  67.70280515542078\n",
      "Latency (Sec/Prompt) :  4.767189249720045\n"
     ]
    }
   ],
   "source": [
    "print(\"******* Proposed Policies: Policy 3: Predict output ******\")\n",
    "# this will be calculated with with function as = f(prediction, ground truth, confidence)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from collections import Counter\n",
    "\n",
    "def collect_input_target(data_temp):\n",
    "    temp_conf = clean(data_temp['confidence'].tolist(), 'conf')\n",
    "    input_conf = [ sigmoid(item) for item in temp_conf]\n",
    "    target_truth = [ [1 if element in item else 0 for element in llms]  for item in data['true_label'].tolist()]\n",
    "    target_conf = [ conf[item.index(1)] if 1 in item else 0.5 for item, conf in zip(target_truth, input_conf) ]\n",
    "    \n",
    "    count = 0\n",
    "    x,y =[], []\n",
    "    for ix, iy in zip(input_conf, target_conf):\n",
    "        if len(ix) == len(llms) and len([iy]) == 1:\n",
    "            x.append(ix)\n",
    "            y.append(iy)\n",
    "        else:\n",
    "            count= count +1\n",
    "    print(\"Incorect Rows:\", count)\n",
    "    return x, y\n",
    "\n",
    "\n",
    "data_train = data_all.loc[data_all['split'] == 'train']\n",
    "data_val = data_all.loc[data_all['split'] == 'val']\n",
    "\n",
    "train_x, train_y = collect_input_target(data_train)\n",
    "val_x, val_y = collect_input_target(data_val)\n",
    "\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(train_x, train_y)\n",
    "\n",
    "y_pred = model.predict(val_x)\n",
    "mse = mean_squared_error(val_y, y_pred)\n",
    "print(f'Mean Squared Error on Dev Set: {mse}')\n",
    "\n",
    "predicted_output = model.predict(conf).tolist()\n",
    "\n",
    "predicted_policy_index =[]\n",
    "for con, pred in zip(conf, predicted_output):\n",
    "    temp_list = [ item-pred for item in con]\n",
    "    argmax = temp_list.index(max(temp_list))\n",
    "    predicted_policy_index.append(argmax)\n",
    "assert len(predicted_policy_index) == len(conf)\n",
    "\n",
    "def policy3(truth_list, pred_ind):\n",
    "    acc_count  = 0    \n",
    "    llm_count = len(llms)*[0]\n",
    "    for item, val in zip(truth_list, pred_ind):\n",
    "        if item[val] == 1:\n",
    "            acc_count += 1\n",
    "            llm_count[val] += 1\n",
    "    return acc_count, llm_count\n",
    "        \n",
    "\n",
    "acc, llm_count_list = policy3(truth, predicted_policy_index)\n",
    "facc = acc/(len(truth))\n",
    "lat = sum([ item*mod2lat[id2mod[i]] for i, item in enumerate(llm_count_list)])\n",
    "flat=lat/sum(llm_count_list)\n",
    "print(\"Accuracy (%): \", facc*100)\n",
    "print(\"Latency (Sec/Prompt) : \", flat)\n",
    "\n",
    "Global_List.append(['Policy3 (Prediction) :',facc*100, flat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c4ab7b8c-2110-4599-84d4-5c630bfe9783",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******* Proposed Policies: Policy 4: Sorted Prediction output ******\n",
      "{'maj_gemma-7b-it_CHAT': 0, 'maj_gemma-7b_LM': 1, 'maj_llama2-13b-chat_CHAT': 2, 'maj_metamath-7b_LM': 3, 'maj_mistral-7b-inst_CHAT': 4, 'maj_mistral-7b-lm_LM': 5}\n",
      "{'maj_gemma-7b-it_CHAT': 0, 'maj_llama2-13b-chat_CHAT': 1, 'maj_mistral-7b-inst_CHAT': 2, 'maj_mistral-7b-lm_LM': 3, 'maj_metamath-7b_LM': 4, 'maj_gemma-7b_LM': 5}\n",
      "{0: 0, 1: 2, 2: 4, 3: 5, 4: 3, 5: 1}\n",
      "Incorect Rows: 0\n",
      "Incorect Rows: 0\n",
      "Mean Squared Error on Dev Set: 0.03729692368496198\n",
      "Accuracy (%):  59.59059893858984\n",
      "Latency (Sec/Prompt) :  4.7732824427480915\n"
     ]
    }
   ],
   "source": [
    "print(\"******* Proposed Policies: Policy 4: Sorted Prediction output ******\")\n",
    "# this will be calculated with with function as = f(prediction, ground truth, confidence)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from collections import Counter\n",
    "\n",
    "# obtain new mapping based on frequency\n",
    "target_truth = [ [1 if element in item else 0 for element in llms]  for item in data['true_label'].tolist()]\n",
    "temp = [ [ id2mod[i] for i, val in enumerate(item) if val !=0 ] for item in target_truth]\n",
    "flattened_list = [item for sublist in temp for item in sublist]\n",
    "element_counts = Counter(flattened_list)\n",
    "\n",
    "sorted_dict = {item:i for i, (item, count) in enumerate(sorted(element_counts.items(), key=lambda x: x[1]))}\n",
    "print(mod2id)\n",
    "print(sorted_dict)\n",
    "map_dict = {}\n",
    "for key, value in sorted_dict.items():\n",
    "    map_dict[sorted_dict[key]] = mod2id[key]\n",
    "print(map_dict)\n",
    "    \n",
    "def collect_input_target(data_temp):\n",
    "    temp_conf = clean(data_temp['confidence'].tolist(), 'conf')\n",
    "    input_conf = [ sigmoid(item) for item in temp_conf]\n",
    "    new_input_conf = [  [ item[map_dict[i]] for i, val in enumerate(item)] for item in input_conf]\n",
    "    \n",
    "    target_truth = [ [1 if element in item else 0 for element in llms]  for item in data['true_label'].tolist()]\n",
    "    new_target_truth = [  [ item[map_dict[i]] for i, val in enumerate(item)] for item in target_truth]\n",
    "    target_conf = [ conf[item.index(1)] if 1 in item else 0.5 for item, conf in zip(new_target_truth, new_input_conf) ]\n",
    "    \n",
    "    count = 0\n",
    "    x,y =[], []\n",
    "    for ix, iy in zip(input_conf, target_conf):\n",
    "        if len(ix) == len(llms) and len([iy]) == 1:\n",
    "            x.append(ix)\n",
    "            y.append(iy)\n",
    "        else:\n",
    "            count= count +1\n",
    "    print(\"Incorect Rows:\", count)\n",
    "    return x, y\n",
    "\n",
    "\n",
    "data_train = data_all.loc[data_all['split'] == 'train']\n",
    "data_val = data_all.loc[data_all['split'] == 'val']\n",
    "\n",
    "train_x, train_y = collect_input_target(data_train)\n",
    "val_x, val_y = collect_input_target(data_val)\n",
    "\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(train_x, train_y)\n",
    "\n",
    "y_pred = model.predict(val_x)\n",
    "mse = mean_squared_error(val_y, y_pred)\n",
    "print(f'Mean Squared Error on Dev Set: {mse}')\n",
    "\n",
    "predicted_output = model.predict(conf).tolist()\n",
    "\n",
    "predicted_policy_index =[]\n",
    "for con, pred in zip(conf, predicted_output):\n",
    "    temp_list = [ item-pred for item in con]\n",
    "    argmax = temp_list.index(max(temp_list))\n",
    "    predicted_policy_index.append(argmax)\n",
    "assert len(predicted_policy_index) == len(conf)\n",
    "\n",
    "def policy4(truth_list, pred_ind):\n",
    "    acc_count  = 0    \n",
    "    llm_count = len(llms)*[0]\n",
    "    for item, val in zip(truth_list, pred_ind):\n",
    "        if item[val] == 1:\n",
    "            acc_count += 1\n",
    "            llm_count[val] += 1\n",
    "    return acc_count, llm_count\n",
    "        \n",
    "\n",
    "new_truth = [  [ item[map_dict[i]] for i, val in enumerate(item)] for item in truth]\n",
    "acc, llm_count_list = policy4(new_truth, predicted_policy_index)\n",
    "facc = acc/(len(new_truth))\n",
    "lat = sum([ item*mod2lat[id2mod[i]] for i, item in enumerate(llm_count_list)])\n",
    "flat=lat/sum(llm_count_list)\n",
    "print(\"Accuracy (%): \", facc*100)\n",
    "print(\"Latency (Sec/Prompt) : \", flat)\n",
    "\n",
    "Global_List.append(['Policy4 (Sorted Prediction) :', facc*100, flat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c35a2eaa-e925-4d7f-8c7a-002110b53497",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy (%)</th>\n",
       "      <th>Latency (Sec/prompt)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Considered LLMs</td>\n",
       "      <td>[maj_gemma-7b-it_CHAT, maj_gemma-7b_LM, maj_ll...</td>\n",
       "      <td>---</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Classifier-f1-weighted</td>\n",
       "      <td>0.705367</td>\n",
       "      <td>000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Oracle</td>\n",
       "      <td>87.187263</td>\n",
       "      <td>3.859391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random</td>\n",
       "      <td>55.378014</td>\n",
       "      <td>3.623332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[maj_gemma-7b-it_CHAT]</td>\n",
       "      <td>36.846096</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[maj_gemma-7b_LM]</td>\n",
       "      <td>71.114481</td>\n",
       "      <td>7.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[maj_llama2-13b-chat_CHAT]</td>\n",
       "      <td>46.702047</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[maj_metamath-7b_LM]</td>\n",
       "      <td>67.551175</td>\n",
       "      <td>4.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[maj_mistral-7b-inst_CHAT]</td>\n",
       "      <td>50.416983</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[maj_mistral-7b-lm_LM]</td>\n",
       "      <td>59.742229</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[maj_gemma-7b-it_CHAT, maj_metamath-7b_LM]</td>\n",
       "      <td>73.085671</td>\n",
       "      <td>2.683402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[maj_gemma-7b_LM, maj_metamath-7b_LM]</td>\n",
       "      <td>81.804397</td>\n",
       "      <td>6.786376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[maj_llama2-13b-chat_CHAT, maj_mistral-7b-inst...</td>\n",
       "      <td>63.002274</td>\n",
       "      <td>1.59302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[maj_gemma-7b_LM, maj_metamath-7b_LM, maj_mist...</td>\n",
       "      <td>84.382108</td>\n",
       "      <td>6.609614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[maj_gemma-7b-it_CHAT, maj_gemma-7b_LM, maj_mi...</td>\n",
       "      <td>78.468537</td>\n",
       "      <td>3.758841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[maj_gemma-7b-it_CHAT, maj_mistral-7b-inst_CHA...</td>\n",
       "      <td>72.251706</td>\n",
       "      <td>1.317314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[maj_gemma-7b-it_CHAT, maj_llama2-13b-chat_CHA...</td>\n",
       "      <td>70.280516</td>\n",
       "      <td>1.618878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[maj_gemma-7b_LM, maj_llama2-13b-chat_CHAT, ma...</td>\n",
       "      <td>85.443518</td>\n",
       "      <td>6.471162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[maj_gemma-7b-it_CHAT, maj_gemma-7b_LM, maj_ll...</td>\n",
       "      <td>80.970432</td>\n",
       "      <td>3.828184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[maj_gemma-7b-it_CHAT, maj_llama2-13b-chat_CHA...</td>\n",
       "      <td>75.511751</td>\n",
       "      <td>1.356426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[maj_gemma-7b-it_CHAT, maj_gemma-7b_LM, maj_ll...</td>\n",
       "      <td>87.187263</td>\n",
       "      <td>3.859391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Upperbound Performance (Classifier)</td>\n",
       "      <td>79.681577</td>\n",
       "      <td>5.160228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Policy1 (ConfArgMax) :</td>\n",
       "      <td>67.62699</td>\n",
       "      <td>4.767265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Policy2 (Select Random) :</td>\n",
       "      <td>67.47536</td>\n",
       "      <td>4.767416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Policy3 (Prediction) :</td>\n",
       "      <td>67.702805</td>\n",
       "      <td>4.767189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Policy4 (Sorted Prediction) :</td>\n",
       "      <td>59.590599</td>\n",
       "      <td>4.773282</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Model  \\\n",
       "0                                     Considered LLMs   \n",
       "1                              Classifier-f1-weighted   \n",
       "2                                              Oracle   \n",
       "3                                              Random   \n",
       "4                              [maj_gemma-7b-it_CHAT]   \n",
       "5                                   [maj_gemma-7b_LM]   \n",
       "6                          [maj_llama2-13b-chat_CHAT]   \n",
       "7                                [maj_metamath-7b_LM]   \n",
       "8                          [maj_mistral-7b-inst_CHAT]   \n",
       "9                              [maj_mistral-7b-lm_LM]   \n",
       "10         [maj_gemma-7b-it_CHAT, maj_metamath-7b_LM]   \n",
       "11              [maj_gemma-7b_LM, maj_metamath-7b_LM]   \n",
       "12  [maj_llama2-13b-chat_CHAT, maj_mistral-7b-inst...   \n",
       "13  [maj_gemma-7b_LM, maj_metamath-7b_LM, maj_mist...   \n",
       "14  [maj_gemma-7b-it_CHAT, maj_gemma-7b_LM, maj_mi...   \n",
       "15  [maj_gemma-7b-it_CHAT, maj_mistral-7b-inst_CHA...   \n",
       "16  [maj_gemma-7b-it_CHAT, maj_llama2-13b-chat_CHA...   \n",
       "17  [maj_gemma-7b_LM, maj_llama2-13b-chat_CHAT, ma...   \n",
       "18  [maj_gemma-7b-it_CHAT, maj_gemma-7b_LM, maj_ll...   \n",
       "19  [maj_gemma-7b-it_CHAT, maj_llama2-13b-chat_CHA...   \n",
       "20  [maj_gemma-7b-it_CHAT, maj_gemma-7b_LM, maj_ll...   \n",
       "21                Upperbound Performance (Classifier)   \n",
       "22                             Policy1 (ConfArgMax) :   \n",
       "23                          Policy2 (Select Random) :   \n",
       "24                             Policy3 (Prediction) :   \n",
       "25                      Policy4 (Sorted Prediction) :   \n",
       "\n",
       "                                         Accuracy (%) Latency (Sec/prompt)  \n",
       "0   [maj_gemma-7b-it_CHAT, maj_gemma-7b_LM, maj_ll...                  ---  \n",
       "1                                            0.705367                  000  \n",
       "2                                           87.187263             3.859391  \n",
       "3                                           55.378014             3.623332  \n",
       "4                                           36.846096                  0.7  \n",
       "5                                           71.114481                  7.1  \n",
       "6                                           46.702047                  1.8  \n",
       "7                                           67.551175                  4.7  \n",
       "8                                           50.416983                  1.0  \n",
       "9                                           59.742229                  3.7  \n",
       "10                                          73.085671             2.683402  \n",
       "11                                          81.804397             6.786376  \n",
       "12                                          63.002274              1.59302  \n",
       "13                                          84.382108             6.609614  \n",
       "14                                          78.468537             3.758841  \n",
       "15                                          72.251706             1.317314  \n",
       "16                                          70.280516             1.618878  \n",
       "17                                          85.443518             6.471162  \n",
       "18                                          80.970432             3.828184  \n",
       "19                                          75.511751             1.356426  \n",
       "20                                          87.187263             3.859391  \n",
       "21                                          79.681577             5.160228  \n",
       "22                                           67.62699             4.767265  \n",
       "23                                           67.47536             4.767416  \n",
       "24                                          67.702805             4.767189  \n",
       "25                                          59.590599             4.773282  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_df = pd.DataFrame(Global_List, columns=[\"Model\", \"Accuracy (%)\", \"Latency (Sec/prompt)\"])\n",
    "global_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5a53f63e-ce78-4f84-b439-404d935718cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "global_df.to_csv(f'./routing_results_{data_name}.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.g5.xlarge",
  "kernelspec": {
   "display_name": "its_v1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
